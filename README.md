# TÃ¼rkÃ§e Åiir Ãœretimi - turkish-gpt2 Modeli ile

Bu proje, YÄ±ldÄ±z Teknik Ãœniversitesi'nin geliÅŸtirdiÄŸi **"turkish-gpt2-large-750m-instruct-v0.1"** modelini kullanarak TÃ¼rkÃ§e ÅŸiir Ã¼retmeyi amaÃ§lamaktadÄ±r. 
Huggingface Transformers kÃ¼tÃ¼phanesi ile GPT-2 tabanlÄ± bu dil modeli, verilen baÅŸlangÄ±Ã§ metninden yola Ã§Ä±karak anlamlÄ± ve yaratÄ±cÄ± TÃ¼rkÃ§e ÅŸiir dizeleri Ã¼retmektedir.

## Proje Ã–zellikleri

- **Model:** ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1 (TÃ¼rkÃ§e GPT-2 bÃ¼yÃ¼k boyutlu model)
- **Girdi:** KullanÄ±cÄ± tarafÄ±ndan belirlenen baÅŸlangÄ±Ã§ ÅŸiir satÄ±rÄ± veya kelime grubu
- **Ã‡Ä±ktÄ±:** Modelin oluÅŸturduÄŸu, anlamlÄ± ve akÄ±cÄ± ÅŸiir dizeleri
- **Teknik:** Huggingface Transformers, PyTorch kullanÄ±larak metin tokenizasyonu ve Ã¼retimi  
- **Ã–zelleÅŸtirme:** Sampling parametreleri (top_k, top_p, temperature, repetition_penalty) ile Ã¼retim Ã§eÅŸitliliÄŸi ve tekrar kontrolÃ¼ saÄŸlanÄ±r
- **SonuÃ§:** Ãœretilen ÅŸiirler konsola yazdÄ±rÄ±lÄ±r ve tarih damgasÄ± ile birlikte `poem.txt` dosyasÄ±na kaydedilir

## KullanÄ±m

Projede Ã¶rnek olarak ÅŸu baÅŸlangÄ±Ã§ metni verilmiÅŸtir: KenetlenmiÅŸsin kalbime, ilmek ilmek,

Bu metin model tarafÄ±ndan iÅŸlenerek yaklaÅŸÄ±k 100 token uzunluÄŸunda ÅŸiir Ã¼retimi yapÄ±lÄ±r.

## AmaÃ§

TÃ¼rkÃ§e doÄŸal dil iÅŸleme alanÄ±nda yaratÄ±cÄ± metin Ã¼retimi iÃ§in yerli kaynaklarÄ±n kullanÄ±lmasÄ± ve geliÅŸtirilmesi hedeflenmektedir. 
Bu Ã§alÄ±ÅŸma, TÃ¼rkÃ§e dilinde ÅŸiir Ã¼retimi yapan modellerin pratik kullanÄ±mÄ±nÄ± gÃ¶stermektedir.

## GeliÅŸtirici Ekip

Bu projede kullanÄ±lan GPT-2 tabanlÄ± TÃ¼rkÃ§e dil modeli, YÄ±ldÄ±z Teknik Ãœniversitesi Cosmos ekibi tarafÄ±ndan geliÅŸtirilmiÅŸtir. 
Daha fazla bilgi ve projeleri incelemek iÃ§in:

ğŸ”— [https://cosmos.yildiz.edu.tr/](https://cosmos.yildiz.edu.tr/)
